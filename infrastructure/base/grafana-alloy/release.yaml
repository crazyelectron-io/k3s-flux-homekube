# infrastructure/base/grafana-alloy/release.yaml 
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: alloy
spec:
  releaseName: alloy
  chart:
    spec:
      chart: alloy
      interval: 22h
      sourceRef:
        kind: HelmRepository
        name: grafana
  interval: 1h
  install:
    remediation:
      retries: 2
  upgrade:
    remediation:
      retries: 2
  values:
    alloy:
      configMap:
        create: true
        content: |-
          logging {
            level = "info"
            format = "logfmt"
          }
          // Define the Loki receiver endpoint to forward logs to.
          loki.write "default" {
            endpoint {
              url = "http://loki.${OBSERVABILITY_NAMESPACE}.svc.cluster.local:3100/loki/api/v1/push"
            }
          }
          // Monitor syslog to scrape node-logs (returns an array of file paths).
          local.file_match "node_logs" {
            path_targets = [{
                __path__  = "/var/log/syslog",
                job       = "node/syslog",
                node_name = env("HOSTNAME"),
                cluster   = "${CLUSTER_NAME}",
            }]
          }
          // Read syslog from the nodes and forward them to the Loki receiver.
          loki.source.file "node_logs" {
            targets    = local.file_match.node_logs.targets
            forward_to = [loki.write.default.receiver]
          }
          // Dynamically find scrape targets from Kubernetes resources by watching cluster state.
          discovery.kubernetes "pod" {
            role = "pod"
            selectors {
              role = "pod"
              field = "spec.nodeName=" + coalesce(env("HOSTNAME"), constants.hostname)
            }
          }
          // Rewrite the label set of the pods by applying relabeling rules.
          discovery.relabel "pod_logs" {
            targets = discovery.kubernetes.pod.targets
            // Label creation - "namespace" field from "__meta_kubernetes_namespace"
            rule {
              source_labels = ["__meta_kubernetes_namespace"]
              action = "replace"
              target_label = "namespace"
            }
            // Label creation - "node" field from "__meta_kubernetes_pod_node_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_node_name"]
              action = "replace"
              target_label = "node"
            }
            // Label creation - "pod" field from "__meta_kubernetes_pod_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_name"]
              action = "replace"
              target_label = "pod"
            }
            // Label creation - "container" field from "__meta_kubernetes_pod_container_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_container_name"]
              action = "replace"
              target_label = "container"
            }
            // Label creation -  "app" field from "__meta_kubernetes_pod_label_app_kubernetes_io_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
              action = "replace"
              target_label = "app"
            }
            // Label creation -  "job" field from "__meta_kubernetes_namespace" and "__meta_kubernetes_pod_container_name"
            rule {
              source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
              action = "replace"
              target_label = "job"
              separator = "/"
              replacement = "$1"
            }
            // Label creation - "container" field from "__meta_kubernetes_pod_uid" and "__meta_kubernetes_pod_container_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
              action = "replace"
              target_label = "__path__"
              separator = "/"
              replacement = "/var/log/pods/*$1/*.log"
            }
            // Label creation -  "container_runtime" field from "__meta_kubernetes_pod_container_id"
            rule {
              source_labels = ["__meta_kubernetes_pod_container_id"]
              action = "replace"
              target_label = "container_runtime"
              regex = "^(\\S+):\\/\\/.+$"
              replacement = "$1"
            }
          }
          // loki.source.kubernetes tails logs from Kubernetes containers using the Kubernetes API.
          loki.source.kubernetes "pod_logs" {
            targets    = discovery.relabel.pod_logs.output
            forward_to = [loki.process.pod_logs.receiver]
          }
          // receive log entries from other Loki components, adds a cluster label to it and
          // forwards the result to the default loki writer.
          loki.process "pod_logs" {
            stage.static_labels {
                values = {
                  cluster = "${CLUSTER_NAME}",
                }
            }
            forward_to = [loki.write.default.receiver]
          }
          // tail events from the Kubernetes API and converts them into log lines to forward to other Loki components.
          loki.source.kubernetes_events "cluster_events" {
            job_name   = "integrations/kubernetes/eventhandler"
            log_format = "logfmt"
            forward_to = [
              loki.process.cluster_events.receiver,
            ]
          }
          // Receive K3s log entries from other loki components, add cluster label and forwards the result
          // to the default loki receiver.
          loki.process "cluster_events" {
            forward_to = [loki.write.default.receiver]
            stage.static_labels {
              values = {
                cluster = "${CLUSTER_NAME}",
              }
            }
            stage.labels {
              values = {
                kubernetes_cluster_events = "job",
              }
            }
          }
          loki.source.syslog "local" {
            listener {
              address = "127.0.0.1:8514"
              protocol = "udp"
              labels   = { component = "loki.source.syslog", protocol = "udp"}
            }
            listener {
              address  = "127.0.0.1:9514"
              labels   = { component = "loki.source.syslog", protocol = "tcp" }
            }
            forward_to = [loki.write.default.receiver]
          }
          // Receive rsyslog entries from other loki components, add label and forward the result
          // to the default loki receiver.
          loki.process "rsyslog_events" {
            forward_to = [loki.write.default.receiver]
            stage.static_labels {
              values = {
                syslog = "homelog",
              }
            }
          }
      # -- Path to where Grafana Alloy stores data (for example, the Write-Ahead Log).
      # By default, data is lost between reboots.
      storagePath: /tmp/alloy
      listenAddr: 0.0.0.0
      listenPort: 12345
      listenScheme: HTTP
      uiPathPrefix: /
      enableReporting: false
      extraPorts: []
      mounts:
        # -- Mount /var/log from the host into the container for log collection.
        varlog: true
        # -- Mount /var/lib/docker/containers from the host into the container for log collection.
        dockercontainers: true
        # -- Extra volume mounts to add into the Grafana Alloy container.
        extra: []
      resources: {}
    image:
      registry: "${HARBOR_REGISTRY}"
      repository: alloy
      tag: v1.3.1
      pullPolicy: IfNotPresent
    # Options for the extra controller used for config reloading.
    configReloader:
      enabled: true
      image:
        registry: "${HARBOR_REGISTRY}"
        repository: configmap-reload  # was: jimmidyson/configmap-reload
        tag: v0.12.0
      customArgs: []
      resources:
        requests:
          cpu: "1m"
          memory: "5Mi"
    controller:
      type: 'daemonset'
      dnsPolicy: ClusterFirst
      updateStrategy: {}
      initContainers: []
    service:
      enabled: true
      type: ClusterIP
      clusterIP: ''
      internalTrafficPolicy: Cluster
      annotations: {}
    serviceMonitor:
      enabled: true
      additionalLabels: {}
      # -- Scrape interval. If not set, the Prometheus default scrape interval is used.
      interval: ""
      # -- MetricRelabelConfigs to apply to samples after scraping, but before ingestion.
      # ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig
      metricRelabelings: []
      # - action: keep
      #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
      #   sourceLabels: [__name__]
      tlsConfig: {}
      # -- RelabelConfigs to apply to samples before scraping
      # ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig
      relabelings: []
      # - sourceLabels: [__meta_kubernetes_pod_node_name]
      #   separator: ;
      #   regex: ^(.*)$
      #   targetLabel: nodename
      #   replacement: $1
      #   action: replace
    ingress:
      # We'll use Traefik IngressRoutes (#TODO: Migrate to Gateway)
      enabled: false
